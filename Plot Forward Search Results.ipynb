{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'size' : 18}\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reward(timesteps, mean_reward, min_reward, max_reward, env_name, figname=\"mean_reward.png\"):\n",
    "    plt.figure(figsize=(11, 7))\n",
    "    plt.plot(timesteps, mean_reward, label='Mean Reward',  color='orangered')\n",
    "    plt.fill_between(timesteps, min_reward, max_reward, color='mistyrose')\n",
    "\n",
    "    axes = plt.gca()\n",
    "    plt.title(\"{} Reward\".format(env_name), fontdict={'size' : 18})\n",
    "    plt.xlabel('Timesteps', fontdict={'size' : 18})\n",
    "    plt.ylabel('Total Cumulative Reward', fontdict={'size' : 18})\n",
    "    plt.ticklabel_format(axis=\"x\", style=\"sci\", scilimits=(0,0))\n",
    "    plt.savefig(figname, dpi=200)\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_seeds_combined(run_dirs, env_name, with_std=True, figname='combined_seeds.png'):\n",
    "    \n",
    "    mean_rewards = []\n",
    "    std_rewards = []\n",
    "    timesteps = []\n",
    "    for run_dir in run_dirs:\n",
    "        train_stats = np.load(os.path.join(run_dir, 'train_stats.npz'))\n",
    "        mean_rewards.append(train_stats['mean_reward'])\n",
    "        std_rewards.append(train_stats['std_reward'])\n",
    "        timesteps.append(train_stats['timesteps'])\n",
    "    \n",
    "    mean_rewards = np.array(mean_rewards)\n",
    "    std_rewards = np.array(std_rewards)\n",
    "    timesteps = np.array(timesteps)[0]\n",
    "    \n",
    "    plt.figure(figsize=(11, 7))\n",
    "    plt.plot(timesteps, mean_rewards[0], label='Mean Reward',  color='orangered')\n",
    "    plt.plot(timesteps, mean_rewards[1], label='Mean Reward',  color='lightseagreen')\n",
    "    plt.plot(timesteps, mean_rewards[2], label='Mean Reward',  color='goldenrod')\n",
    "    if with_std:\n",
    "        plt.fill_between(timesteps, mean_rewards[0] - std_rewards[0], mean_rewards[0] + std_rewards[0], color='mistyrose')\n",
    "        plt.fill_between(timesteps, mean_rewards[1] - std_rewards[1], mean_rewards[1] + std_rewards[1], color='paleturquoise')\n",
    "        plt.fill_between(timesteps, mean_rewards[2] - std_rewards[2], mean_rewards[2] + std_rewards[2], color='lightgoldenrodyellow')\n",
    "\n",
    "    axes = plt.gca()\n",
    "    plt.title(\"{} Reward\".format(env_name), fontdict={'size' : 18})\n",
    "    plt.xlabel('Timesteps', fontdict={'size' : 18})\n",
    "    plt.ylabel('Total Cumulative Reward', fontdict={'size' : 18})\n",
    "    plt.ticklabel_format(axis=\"x\", style=\"sci\", scilimits=(0,0))\n",
    "    \n",
    "    log_dir = run_dirs[0].rsplit('/', 1)[0]\n",
    "    plt.savefig(os.path.join(log_dir, figname), dpi=200)\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_seeds(run_dirs, env_name, with_std=True, figname='seeds.png'):\n",
    "    \n",
    "    mean_rewards = []\n",
    "    timesteps = []\n",
    "    for run_dir in run_dirs:\n",
    "        train_stats = np.load(os.path.join(run_dir, 'train_stats.npz'))\n",
    "        mean_rewards.append(train_stats['mean_reward'])\n",
    "        timesteps.append(train_stats['timesteps'])\n",
    "    \n",
    "    mean_reward = np.mean(np.array(mean_rewards), axis = 0)\n",
    "    std_reward = np.std(np.array(mean_rewards), axis = 0)\n",
    "    timesteps = np.array(timesteps)[0]\n",
    "    \n",
    "    log_dir = run_dirs[0].rsplit('/', 1)[0]\n",
    "    plot_reward(timesteps, mean_reward, mean_reward - std_reward, mean_reward + std_reward, env_name, figname=os.path.join(log_dir, figname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_epochs(epoch_dirs, ev_name, with_std=True, figname='seeds.png'):\n",
    "    plt.figure(figsize=(11, 7))\n",
    "    means = []\n",
    "    stds = []\n",
    "    ind2epoch = {0: 10, 1: 20, 2: 50}\n",
    "    mean_colors = ['orangered', 'lightseagreen', 'goldenrod']\n",
    "    fill_colors = ['mistyrose', 'paleturquoise', 'khaki']\n",
    "    alphas = [0.5, 0.3, 0.3, 0.2]\n",
    "    for ind, run_dir in enumerate(epoch_dirs[:3]):\n",
    "        mean = []\n",
    "        timesteps = []\n",
    "        for indi in range(ind, 9, 3):\n",
    "            run_dir = epoch_dirs[indi]\n",
    "            train_stats = np.load(os.path.join(run_dir, 'train_stats.npz'))\n",
    "            mean.append(train_stats['mean_reward'])\n",
    "            timesteps.append(train_stats['timesteps'])\n",
    "    \n",
    "        mean = np.mean(np.array(mean), axis = 0)\n",
    "        std = np.std(np.array(mean), axis = 0)\n",
    "        timesteps = np.array(timesteps)[0]\n",
    "        means.append(mean)\n",
    "        stds.append(std)\n",
    "        \n",
    "        plt.plot(timesteps, mean, label='Mean Reward (Epoch {})'.format(ind2epoch[ind]),  color=mean_colors[ind])\n",
    "        if with_std:\n",
    "            plt.fill_between(timesteps, mean - std, mean + std, color=fill_colors[ind], alpha=alphas[ind])\n",
    "\n",
    "    mean_rewards = np.array(means)\n",
    "    std_rewards = np.array(stds)\n",
    "    \n",
    "    axes = plt.gca()\n",
    "    plt.title(\"{} Reward\".format(env_name), fontdict={'size' : 18})\n",
    "    plt.xlabel('Timesteps', fontdict={'size' : 18})\n",
    "    plt.ylabel('Total Cumulative Reward', fontdict={'size' : 18})\n",
    "    plt.ticklabel_format(axis=\"x\", style=\"sci\", scilimits=(0,0))\n",
    "    plt.legend()\n",
    "    # plt.xticks(list(np.arange(0, (math.ceil(timesteps[-1] / timesteps_interval) + 1) * timesteps_interval, timesteps_interval)), ('{}'.format(str(x)) for x in np.arange(0, (math.ceil(timesteps[-1] / timesteps_interval) + 1) * timesteps_interval, timesteps_interval)))\n",
    "\n",
    "    log_dir = epoch_dirs[0].rsplit('/', 2)[0]\n",
    "    plt.savefig(os.path.join(log_dir, figname), dpi=200)\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forward_search_with_single_process(epoch_dir, env_name, with_std=True, figname='seeds.png'):\n",
    "    run_dirs = []\n",
    "    single_process = [os.path.join(epoch_dir, 'run{}'.format(x)) for x in range(1, 4)]\n",
    "    forward_search_pop_size_1 = [os.path.join(epoch_dir, 'run{}'.format(x)) for x in range(4, 7)]\n",
    "    forward_search_pop_size_3 = [os.path.join(epoch_dir, 'run{}'.format(x)) for x in range(7, 10)]\n",
    "    forward_search_pop_size_5 = [os.path.join(epoch_dir, 'run{}'.format(x)) for x in range(10, 13)]\n",
    "    \n",
    "    run_dirs = single_process + forward_search_pop_size_1 + forward_search_pop_size_3 + forward_search_pop_size_5\n",
    "    \n",
    "    plt.figure(figsize=(11, 7))\n",
    "    mean = []\n",
    "    ind2epoch = {1: 10, 1: 1, 2: 3, 3: 5}\n",
    "    label_names = ['Without EPS', 'EPS: K = 1', 'EPS: K = 3', 'EPS: K = 5']\n",
    "    mean_colors = ['orangered', 'lightseagreen', 'goldenrod', 'darkorchid']\n",
    "    fill_colors = ['mistyrose', 'paleturquoise', 'khaki', 'mediumpurple']\n",
    "    alphas = [0.5, 0.3, 0.3, 0.2]\n",
    "    for ind, run_dir in enumerate(run_dirs):\n",
    "        timesteps = []\n",
    "        train_stats = np.load(os.path.join(run_dirs[ind], 'train_stats.npz'))\n",
    "        mean.append(train_stats['mean_reward'])\n",
    "        timesteps.append(train_stats['timesteps'])\n",
    "        timesteps = np.array(timesteps)[0]\n",
    "\n",
    "        if (ind + 1) % 3 == 0:\n",
    "            mean = np.mean(np.array(mean), axis = 0)\n",
    "            std = np.std(np.array(mean), axis = 0)\n",
    "            plt.plot(timesteps, mean, label=label_names[ind // 3],  color=mean_colors[ind // 3])\n",
    "            if with_std:\n",
    "                plt.fill_between(timesteps, mean - std, mean + std, color=fill_colors[ind // 3], alpha=alphas[ind // 3])\n",
    "            \n",
    "            mean = []\n",
    "\n",
    "    axes = plt.gca()\n",
    "    plt.title(\"{} Reward\".format(env_name), fontdict={'size' : 18})\n",
    "    plt.xlabel('Timesteps', fontdict={'size' : 18})\n",
    "    plt.ticklabel_format(axis=\"x\", style=\"sci\", scilimits=(0,0))\n",
    "    plt.ylabel('Total Cumulative Reward', fontdict={'size' : 18})\n",
    "    plt.legend()\n",
    "    # plt.xticks(list(np.arange(0, (math.ceil(timesteps[-1] / timesteps_interval) + 1) * timesteps_interval, timesteps_interval)), ('{}'.format(str(x)) for x in np.arange(0, (math.ceil(timesteps[-1] / timesteps_interval) + 1) * timesteps_interval, timesteps_interval)))\n",
    "\n",
    "    log_dir = epoch_dir.rsplit('/', 1)[0]\n",
    "    plt.savefig(os.path.join(log_dir, figname), dpi=200)\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forward_search_with_single_process_computation(epoch_dir, env_name, with_std=True, figname='seeds.png'):\n",
    "    run_dirs = []\n",
    "    single_process = [os.path.join(epoch_dir, 'run{}'.format(x)) for x in range(1, 4)]\n",
    "    forward_search_pop_size_1 = [os.path.join(epoch_dir, 'run{}'.format(x)) for x in range(4, 7)]\n",
    "    forward_search_pop_size_3 = [os.path.join(epoch_dir, 'run{}'.format(x)) for x in range(7, 10)]\n",
    "    forward_search_pop_size_5 = [os.path.join(epoch_dir, 'run{}'.format(x)) for x in range(10, 13)]\n",
    "    \n",
    "    run_dirs = single_process + forward_search_pop_size_1 + forward_search_pop_size_3 + forward_search_pop_size_5\n",
    "    \n",
    "    plt.figure(figsize=(11, 7))\n",
    "    mean = []\n",
    "    ind2epoch = {0: 1, 1: 1, 2: 3, 3: 5}\n",
    "    label_names = ['Without EPS', 'EPS: K = 1', 'EPS: K = 3', 'EPS: K = 5']\n",
    "    mean_colors = ['orangered', 'lightseagreen', 'goldenrod', 'darkorchid']\n",
    "    fill_colors = ['mistyrose', 'paleturquoise', 'khaki', 'mediumpurple']\n",
    "    alphas = [0.5, 0.3, 0.3, 0.2]\n",
    "    for ind, run_dir in enumerate(run_dirs):\n",
    "        timesteps = []\n",
    "        train_stats = np.load(os.path.join(run_dirs[ind], 'train_stats.npz'))\n",
    "        mean.append(train_stats['mean_reward'])\n",
    "        timesteps.append(train_stats['timesteps'])\n",
    "        timesteps = np.array(timesteps)[0]\n",
    "\n",
    "        if (ind + 1) % 3 == 0:\n",
    "            mean = np.mean(np.array(mean), axis = 0)\n",
    "            std = np.std(np.array(mean), axis = 0)\n",
    "            \n",
    "            if (ind // 3) >= 2:\n",
    "                k = ind2epoch[ind // 3]\n",
    "                timesteps = timesteps[::3]\n",
    "                mean = mean[:int(timesteps.shape[0])]\n",
    "            plt.plot(timesteps, mean, label=label_names[ind // 3],  color=mean_colors[ind // 3])\n",
    "            if with_std:\n",
    "                plt.fill_between(timesteps, mean - std, mean + std, color=fill_colors[ind // 3], alpha=alphas[ind // 3])\n",
    "            \n",
    "            mean = []\n",
    "\n",
    "    axes = plt.gca()\n",
    "    plt.title(\"{} Reward\".format(env_name), fontdict={'size' : 18})\n",
    "    plt.xlabel('Timesteps', fontdict={'size' : 18})\n",
    "    plt.ticklabel_format(axis=\"x\", style=\"sci\", scilimits=(0,0))\n",
    "    plt.ylabel('Total Cumulative Reward', fontdict={'size' : 18})\n",
    "    plt.legend()\n",
    "    # plt.xticks(list(np.arange(0, (math.ceil(timesteps[-1] / timesteps_interval) + 1) * timesteps_interval, timesteps_interval)), ('{}'.format(str(x)) for x in np.arange(0, (math.ceil(timesteps[-1] / timesteps_interval) + 1) * timesteps_interval, timesteps_interval)))\n",
    "\n",
    "    log_dir = epoch_dir.rsplit('/', 1)[0]\n",
    "    plt.savefig(os.path.join(log_dir, figname), dpi=200)\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forward_search_with_same_computation(env_dir, env_name, with_std=True, figname='seeds.png'):\n",
    "    run_dirs = []\n",
    "#     single_process = [os.path.join(epoch_dir, 'run{}'.format(x)) for x in range(1, 4)]\n",
    "#     forward_search_pop_size_1 = [os.path.join(epoch_dir, 'run{}'.format(x)) for x in range(4, 7)]\n",
    "#     forward_search_pop_size_3 = [os.path.join(epoch_dir, 'run{}'.format(x)) for x in range(7, 10)]\n",
    "    single_process = [os.path.join(os.path.join(env_dir, '10000000_250'), 'run{}'.format(x)) for x in range(13, 16)]\n",
    "    forward_search_pop_size_3 = [os.path.join(os.path.join(env_dir, '3320000_83'), 'run{}'.format(x)) for x in range(16, 19)]\n",
    "    forward_search_pop_size_5 = [os.path.join(os.path.join(env_dir, '2000000_50'), 'run{}'.format(x)) for x in range(10, 13)]\n",
    "    \n",
    "    run_dirs = single_process + forward_search_pop_size_3 + forward_search_pop_size_5\n",
    "    \n",
    "    plt.figure(figsize=(11, 7))\n",
    "    mean = []\n",
    "    ind2epoch = {0: 1, 1: 3, 2: 5}\n",
    "    label_names = ['Without EPS', 'EPS: K = 3', 'EPS: K = 5']\n",
    "    mean_colors = ['orangered', 'lightseagreen', 'darkorchid']\n",
    "    fill_colors = ['mistyrose', 'paleturquoise', 'mediumpurple']\n",
    "    alphas = [0.5, 0.3, 0.2]\n",
    "    for ind, run_dir in enumerate(run_dirs):\n",
    "        timesteps = []\n",
    "        train_stats = np.load(os.path.join(run_dirs[ind], 'train_stats.npz'))\n",
    "        mean.append(train_stats['mean_reward'])\n",
    "        timesteps.append(train_stats['timesteps'])\n",
    "        timesteps = np.array(timesteps)[0]\n",
    "\n",
    "        if (ind + 1) % 3 == 0:\n",
    "            mean = np.mean(np.array(mean), axis = 0)\n",
    "            std = np.std(np.array(mean), axis = 0)\n",
    "            timesteps = timesteps * ind2epoch[ind // 3]\n",
    "            plt.plot(timesteps, mean, label=label_names[ind // 3],  color=mean_colors[ind // 3])\n",
    "            if with_std:\n",
    "                plt.fill_between(timesteps, mean - std, mean + std, color=fill_colors[ind // 3], alpha=alphas[ind // 3])\n",
    "            \n",
    "            mean = []\n",
    "\n",
    "    axes = plt.gca()\n",
    "    plt.title(\"{} Reward\".format(env_name), fontdict={'size' : 18})\n",
    "    plt.xlabel('Computation Steps', fontdict={'size' : 18})\n",
    "    plt.ylabel('Total Cumulative Reward', fontdict={'size' : 18})\n",
    "    plt.legend()\n",
    "    # plt.xticks(list(np.arange(0, (math.ceil(timesteps[-1] / timesteps_interval) + 1) * timesteps_interval, timesteps_interval)), ('{}'.format(str(x)) for x in np.arange(0, (math.ceil(timesteps[-1] / timesteps_interval) + 1) * timesteps_interval, timesteps_interval)))\n",
    "\n",
    "    plt.savefig(os.path.join(env_dir, figname), dpi=200)\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_epoch_results(epoch, epoch_dir, env_name):\n",
    "    single_process = [os.path.join(epoch_dir, 'run{}'.format(x)) for x in range(1, 4)]\n",
    "    forward_search_pop_size_1 = [os.path.join(epoch_dir, 'run{}'.format(x)) for x in range(4, 7)]\n",
    "    forward_search_pop_size_3 = [os.path.join(epoch_dir, 'run{}'.format(x)) for x in range(7, 10)]\n",
    "    forward_search_pop_size_5 = [os.path.join(epoch_dir, 'run{}'.format(x)) for x in range(10, 13)]\n",
    "    \n",
    "    # To Combine individual seeds plots\n",
    "    plot_seeds_combined(single_process, env_name, figname=\"epochs_{}_combined_seeds.png\".format(epoch))\n",
    "    plot_seeds_combined(forward_search_pop_size_1, env_name, figname=\"epochs_{}_combined_seeds_fs_1.png\".format(epoch))\n",
    "    plot_seeds_combined(forward_search_pop_size_3, env_name, figname=\"epochs_{}_combined_seeds_fs_3.png\".format(epoch))\n",
    "    plot_seeds_combined(forward_search_pop_size_5, env_name, figname=\"epochs_{}_combined_seeds_fs_5.png\".format(epoch))\n",
    "    \n",
    "    # To plot individual seeds mean and the variance between them.\n",
    "    plot_seeds(single_process, env_name, figname=\"epochs_{}_seeds.png\".format(epoch))\n",
    "    plot_seeds(forward_search_pop_size_1, env_name, figname=\"epochs_{}_seeds_fs_1.png\".format(epoch))\n",
    "    plot_seeds(forward_search_pop_size_3, env_name, figname=\"epochs_{}_seeds_fs_3.png\".format(epoch))\n",
    "    plot_seeds(forward_search_pop_size_5, env_name, figname=\"epochs_{}_seeds_fs_5.png\".format(epoch))\n",
    "    \n",
    "    # To plot with and without forward search.\n",
    "    plot_forward_search_with_single_process(epoch_dir, env_name, figname=\"epochs_{}_w_wo_eps.png\".format(epoch))\n",
    "#     plot_forward_search_with_single_process_computation(epoch_dir, env_name, figname=\"epochs_{}_w_wo_eps_w_comp.png\".format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# envs = [('MountainCarContinuous-v0', 1000000), ('Walker2d-v2', 2000000), ('Hopper-v2', 2000000), ('HalfCheetah-v2', 2000000), ('Swimmer-v2', 2000000)]\n",
    "envs = [('Walker2d-v2', 2000000), ('Hopper-v2', 2000000), ('HalfCheetah-v2', 2000000), ('Swimmer-v2', 2000000)]\n",
    "log_dir = '/media/hdd/tanmaya/projects/GymExperiments'\n",
    "epochs = [10, 20, 50]\n",
    "    \n",
    "for env_name, num_timesteps in envs:\n",
    "    for epoch in epochs:\n",
    "        epoch_dir = os.path.join(log_dir, env_name, '{}_{}'.format(num_timesteps, epoch))\n",
    "        generate_epoch_results(epoch, epoch_dir, env_name)\n",
    "    \n",
    "    plot_forward_search_with_same_computation(os.path.join(log_dir, env_name), env_name, figname=\"epochs_50_fs_5_same_computation.png\")\n",
    "    \n",
    "    epoch_dirs = [os.path.join(log_dir, env_name, '{}_{}'.format(num_timesteps, epoch)) for epoch in epochs]\n",
    "    \n",
    "    single_process = [os.path.join(epoch_dir, 'run{}'.format(x)) for x in range(1, 4) for epoch_dir in epoch_dirs]\n",
    "    forward_search_pop_size_1 = [os.path.join(epoch_dir, 'run{}'.format(x)) for x in range(4, 7) for epoch_dir in epoch_dirs]\n",
    "    forward_search_pop_size_3 = [os.path.join(epoch_dir, 'run{}'.format(x)) for x in range(7, 10) for epoch_dir in epoch_dirs]\n",
    "    forward_search_pop_size_5 = [os.path.join(epoch_dir, 'run{}'.format(x)) for x in range(10, 13) for epoch_dir in epoch_dirs]\n",
    "    \n",
    "    plot_epochs(single_process, env_name, figname=\"single_process.png\")\n",
    "    plot_epochs(forward_search_pop_size_1, env_name, figname=\"forward_search_pop_size_1.png\")\n",
    "    plot_epochs(forward_search_pop_size_3, env_name, figname=\"forward_search_pop_size_3.png\")\n",
    "    plot_epochs(forward_search_pop_size_5, env_name, figname=\"forward_search_pop_size_5.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_name, skip_ind=1, delimiter=','):\n",
    "    complete_data = []\n",
    "    with open(file_name, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        lines = lines[::skip_ind]\n",
    "        for line in lines:\n",
    "            line = line.split(',')[:4]\n",
    "            data = []\n",
    "            for x in line:\n",
    "                data.append(float(x))\n",
    "            complete_data.append(data)\n",
    "    \n",
    "    return np.array(complete_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_file(log_path, run_path, indexes):\n",
    "    successes = []\n",
    "    rewards = []\n",
    "    timesteps = []\n",
    "    completed_timestep = []\n",
    "    \n",
    "    if 'with_EPS' in run_path:\n",
    "        skip_ind = int(run_path.split('_')[2])\n",
    "    else:\n",
    "        skip_ind = 1\n",
    "\n",
    "    new_rewards = {}\n",
    "    new_success = {}\n",
    "    for j in indexes:\n",
    "        try:\n",
    "            file_name = os.path.join(log_path, run_path, \"run{}.csv\".format(j))\n",
    "            data = read_file(file_name, skip_ind=skip_ind, delimiter=',')\n",
    "            \n",
    "            epochs = data[:, 0]\n",
    "            completed_timestep.append(epochs.shape[0])\n",
    "            if 'with_EPS' in run_path:\n",
    "                success = data[:, 2]\n",
    "                reward = data[:, 3]\n",
    "            else:\n",
    "                success = data[:, 1]\n",
    "                reward = data[:, 2]\n",
    "            for idx in range(epochs.shape[0]):\n",
    "                new_rewards.setdefault(epochs[idx], []).append(reward[idx])\n",
    "                new_success.setdefault(epochs[idx], []).append(success[idx])\n",
    "\n",
    "            successes.append(success)\n",
    "            rewards.append(reward)\n",
    "            timesteps.append(epochs)\n",
    "        except Exception as e:\n",
    "            print(\"********** File Not Found: {} **********\".format(file_name))\n",
    "            print(e)\n",
    "            print(traceback.format_exc())\n",
    "    \n",
    "    return new_rewards, new_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_datapoints(new_rewards, new_success, dir_name, test_results=False):\n",
    "    mean_reward = []\n",
    "    min_reward = []\n",
    "    max_reward = []\n",
    "\n",
    "    mean_success = []\n",
    "    min_success = []\n",
    "    max_success = []\n",
    "    timesteps = []\n",
    "    for key in sorted(new_rewards):\n",
    "        if 'without_EPS' in dir_name or test_results:\n",
    "            timesteps.append(key / 1000000)\n",
    "        else:\n",
    "            timesteps.append(round(key * 0.12, 2))\n",
    "        mean_reward.append(statistics.mean(new_rewards[key]))\n",
    "        min_reward.append(min(new_rewards[key]))\n",
    "        max_reward.append(max(new_rewards[key]))\n",
    "        \n",
    "        mean_success.append(statistics.mean(new_success[key]))\n",
    "        min_success.append(min(new_success[key]))\n",
    "        max_success.append(max(new_success[key]))\n",
    "        \n",
    "    return mean_reward, min_reward, max_reward, mean_success, min_success, max_success, timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reward_CARLA(log_path, timesteps, mean_reward, min_reward, max_reward, test_results=False, with_std=True, figname=\"mean_reward.png\"):\n",
    "    plt.figure(figsize=(11, 7))\n",
    "\n",
    "    if not test_results:\n",
    "        label_names = ['Without EPS', 'EPS: K = 1', 'EPS: K = 3', 'EPS: K = 5']\n",
    "        mean_colors = ['orangered', 'lightseagreen', 'goldenrod', 'darkorchid']\n",
    "        fill_colors = ['mistyrose', 'paleturquoise', 'khaki', 'mediumpurple']\n",
    "        alphas = [0.5, 0.3, 0.3, 0.2]\n",
    "    else:\n",
    "#         label_names = ['with state A', 'with state A+I', 'with state I']\n",
    "        label_names = ['Navigation task']\n",
    "        mean_colors = ['orangered', 'lightseagreen', 'goldenrod']\n",
    "        fill_colors = ['mistyrose', 'paleturquoise', 'khaki']\n",
    "        alphas = [0.5, 0.3, 0.2]\n",
    "    \n",
    "    for ind in range(len(timesteps)):\n",
    "        tsteps = [s * 1000000 for s in timesteps[ind]]\n",
    "        plt.plot(tsteps, mean_reward[ind], label=label_names[ind], color=mean_colors[ind])\n",
    "        if with_std:\n",
    "            plt.fill_between(tsteps, min_reward[ind], max_reward[ind], color=fill_colors[ind], alpha=alphas[ind])\n",
    "\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim()\n",
    "    if not test_results:\n",
    "        axes.set_ylim(top=140000, bottom=-5000)\n",
    "        plt.title(\"CARLA Reward\", fontdict={'size' : 18})\n",
    "    else:\n",
    "        axes.set_ylim(top=140000, bottom=-150000)\n",
    "#         plt.title(\"Cumulative Reward with Dynamic Actors\", fontdict={'size' : 18})\n",
    "        plt.title(\"Cumulative Reward on Navigation task\", fontdict={'size' : 18})\n",
    "    # plt.legend(loc='lower right', prop={'size' : 36})\n",
    "    \n",
    "    plt.xlabel('Timesteps', fontdict={'size' : 18})\n",
    "    plt.ylabel('Total Cumulative Reward', fontdict={'size' : 18})\n",
    "    plt.ticklabel_format(axis=\"x\", style=\"sci\", scilimits=(0,0))\n",
    "    plt.legend()\n",
    "#     plt.xticks(list(np.arange(0, (math.ceil(timesteps[-1] / 0.5) + 1) * 0.5, 0.5)), ('{}'.format(str(x)) for x in np.arange(0, (math.ceil(timesteps[-1] / 0.5) + 1) * 0.5, 0.5)))\n",
    "    plt.savefig(os.path.join(log_path, figname), dpi=200)\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_success_CARLA(log_path, timesteps, mean_success, min_success, max_success, test_results=False, with_std=True, figname=\"mean_success.png\"):\n",
    "    plt.figure(figsize=(11, 7))\n",
    "\n",
    "    if not test_results:\n",
    "        label_names = ['Without EPS', 'EPS: K = 1', 'EPS: K = 3', 'EPS: K = 5']\n",
    "        mean_colors = ['orangered', 'lightseagreen', 'goldenrod', 'darkorchid']\n",
    "        fill_colors = ['mistyrose', 'paleturquoise', 'khaki', 'mediumpurple']\n",
    "        alphas = [0.5, 0.3, 0.3, 0.2]\n",
    "    else:\n",
    "        label_names = ['with state A', 'with state A+I', 'with state I']\n",
    "#         label_names = ['Navigation task']\n",
    "        mean_colors = ['orangered', 'lightseagreen', 'goldenrod']\n",
    "        fill_colors = ['mistyrose', 'paleturquoise', 'khaki']\n",
    "        alphas = [0.5, 0.3, 0.2]\n",
    "    \n",
    "    for ind in range(len(timesteps)):\n",
    "        tsteps = [s * 1000000 for s in timesteps[ind]]\n",
    "        plt.plot(tsteps, mean_success[ind], label=label_names[ind], color=mean_colors[ind])\n",
    "        if with_std:\n",
    "            plt.fill_between(tsteps, min_success[ind], max_success[ind], color=fill_colors[ind], alpha=alphas[ind])\n",
    "\n",
    "    axes = plt.gca()\n",
    "    # plt.legend(loc='lower right', prop={'size' : 36})\n",
    "    if not test_results:\n",
    "        plt.title(\"CARLA Success Metric\", fontdict={'size' : 18})\n",
    "    else:\n",
    "        plt.title(\"Cumulative Success Metric with Dynamic Actors\", fontdict={'size' : 18})\n",
    "#         plt.title(\"Cumulative Success Metric on Navigation task\", fontdict={'size' : 18})\n",
    "    plt.xlabel('Timesteps', fontdict={'size' : 18})\n",
    "    plt.ylabel('Total Successes', fontdict={'size' : 18})\n",
    "    plt.ticklabel_format(axis=\"x\", style=\"sci\", scilimits=(0,0))\n",
    "    plt.legend()\n",
    "#     plt.xticks(list(np.arange(0, (math.ceil(timesteps[-1] / 0.5) + 1) * 0.5, 0.5)), ('{}'.format(str(x)) for x in np.arange(0, (math.ceil(timesteps[-1] / 0.5) + 1) * 0.5, 0.5)))\n",
    "    plt.savefig(os.path.join(log_path, figname), dpi=200)\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "import statistics\n",
    "\n",
    "\n",
    "log_path = \"./CARLA/\"\n",
    "carla_dirs = ['without_EPS', 'with_EPS_1', 'with_EPS_3', 'with_EPS_5']\n",
    "indexes = [1, 2, 3]\n",
    "\n",
    "mean_rewards = []\n",
    "min_rewards = []\n",
    "max_rewards = []\n",
    "mean_success = []\n",
    "min_success = []\n",
    "max_success = []\n",
    "steps = []\n",
    "for dir_name in carla_dirs:\n",
    "    r, s = get_data_from_file(log_path, dir_name, indexes)\n",
    "    rmean, rmin, rmax, smean, smin, smax, timesteps = compute_datapoints(r, s, dir_name)\n",
    "    \n",
    "    mean_rewards.append(rmean)\n",
    "    min_rewards.append(rmin)\n",
    "    max_rewards.append(rmax)\n",
    "    mean_success.append(smean)\n",
    "    min_success.append(smin)\n",
    "    max_success.append(smax)\n",
    "    steps.append(timesteps)\n",
    "plot_reward_CARLA(log_path, steps, mean_rewards, min_rewards, max_rewards, with_std=True, figname=\"mean_reward.png\")\n",
    "plot_success_CARLA(log_path, steps, mean_success, min_success, max_success, with_std=True, figname=\"mean_success.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "import statistics\n",
    "\n",
    "\n",
    "log_path = \"./Dynamic_CARLA/\"\n",
    "carla_dirs = ['A', 'A_I', 'I']\n",
    "indexes = [1, 2, 3]\n",
    "\n",
    "mean_rewards = []\n",
    "min_rewards = []\n",
    "max_rewards = []\n",
    "mean_success = []\n",
    "min_success = []\n",
    "max_success = []\n",
    "steps = []\n",
    "for dir_name in carla_dirs:\n",
    "    r, s = get_data_from_file(log_path, dir_name, indexes)\n",
    "    rmean, rmin, rmax, smean, smin, smax, timesteps = compute_datapoints(r, s, dir_name, test_results=True)\n",
    "    \n",
    "    mean_rewards.append(rmean)\n",
    "    min_rewards.append(rmin)\n",
    "    max_rewards.append(rmax)\n",
    "    mean_success.append(smean)\n",
    "    min_success.append(smin)\n",
    "    max_success.append(smax)\n",
    "    steps.append(timesteps)\n",
    "plot_reward_CARLA(log_path, steps, mean_rewards, min_rewards, max_rewards, test_results=True, with_std=True, figname=\"mean_reward.png\")\n",
    "plot_success_CARLA(log_path, steps, mean_success, min_success, max_success, test_results=True, with_std=True, figname=\"mean_success.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "import statistics\n",
    "\n",
    "\n",
    "log_path = \"./Static_CARLA/\"\n",
    "dir_name = 'NeurIPS'\n",
    "indexes = [1, 2, 3]\n",
    "\n",
    "mean_rewards = []\n",
    "min_rewards = []\n",
    "max_rewards = []\n",
    "mean_success = []\n",
    "min_success = []\n",
    "max_success = []\n",
    "steps = []\n",
    "# for dir_name in carla_dirs:\n",
    "r, s = get_data_from_file(log_path, dir_name, indexes)\n",
    "rmean, rmin, rmax, smean, smin, smax, timesteps = compute_datapoints(r, s, dir_name, test_results=True)\n",
    "\n",
    "mean_rewards.append(rmean)\n",
    "min_rewards.append(rmin)\n",
    "max_rewards.append(rmax)\n",
    "mean_success.append(smean)\n",
    "min_success.append(smin)\n",
    "max_success.append(smax)\n",
    "steps.append(timesteps)\n",
    "plot_reward_CARLA(log_path, steps, mean_rewards, min_rewards, max_rewards, test_results=True, with_std=True, figname=\"mean_reward.png\")\n",
    "plot_success_CARLA(log_path, steps, mean_success, min_success, max_success, test_results=True, with_std=True, figname=\"mean_success.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla9.4_py35_new",
   "language": "python",
   "name": "carla9.4_py35_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
